<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="DccZuuiZ9TibZPtIaFy53R0h-H4tYt01uuNFgpAariI">
    <meta name="naver-site-verification" content="5e23bdf515b07e9f67d160f17584530e5971e0ab">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content>
    <meta name="keyword" content>
    <link rel="shortcut icon" href="/img/favicon.ico">
    <title>
        
          ICT멘토링 딥러닝 교육 1일차 - kwon | kwon&#39;s Blog
        
    </title>
    <link rel="canonical" href="https://kyu9341.github.io/machinelearning/2019/11/23/2019-11-23-marchinelearning3/">

    <link rel="canonical" href="https://kyu9341.github.io/MachineLearning/2019/11/23/2019-11-23-marchinelearning3/">

    <!-- Bootstrap Core CSS -->
    
<link rel="stylesheet" href="/css/bootstrap.min.css">


    <!-- Custom CSS -->
    
<link rel="stylesheet" href="/css/hux-blog.min.css">


    <!-- Pygments Highlight CSS -->
    
<link rel="stylesheet" href="/css/highlight.css">


    <!-- Custom Fonts -->
    <!-- <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css"> -->
    <!-- Hux change font-awesome CDN to qiniu -->
    <link href="https://cdn.staticfile.org/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">


    <!-- Hux Delete, sad but pending in China
    <link href='http://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/
    css'>
    -->


    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- ga & ba script hoook -->
    <script></script>
<meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/feed.xml" title="kwon's Blog" type="application/atom+xml">
</head>


<!-- hack iOS CSS :active style -->
<body ontouchstart>

    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">kwon&#39;s Blog</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <!-- Known Issue, found by Hux:
            <nav>'s height woule be hold on by its content.
            so, when navbar scale out, the <nav> will cover tags.
            also mask any touch event of tags, unfortunately.
        -->
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">Home</a>
                    </li>

                    

                        
                    

                        
                        <li>
                            <a href="/about/">About</a>
                        </li>
                        
                    

                        
                        <li>
                            <a href="/tags/">Tags</a>
                        </li>
                        
                    

                        
                        <li>
                            <a href="/archives/">Posts</a>
                        </li>
                        
                    

                        
                    
                    
                </ul>
            </div>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>
<script>
    // Drop Bootstarp low-performance Navbar
    // Use customize navbar with high-quality material design animation
    // in high-perf jank-free CSS3 implementation
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    $toggle.addEventListener('click', handleMagic)
    function handleMagic(e){
        if ($navbar.className.indexOf('in') > 0) {
        // CLOSE
            $navbar.className = " ";
            // wait until animation end.
            setTimeout(function(){
                // prevent frequently toggle
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        }else{
        // OPEN
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }
</script>


    <!-- Main Content -->
    
<!-- Image to hack wechat -->
<!-- <img src="https://kyu9341.github.io/img/icon_wechat.png" width="0" height="0"> -->
<!-- <img src="{{ site.baseurl }}/{% if page.header-img %}{{ page.header-img }}{% else %}{{ site.header-img }}{% endif %}" width="0" height="0"> -->

<!-- Post Header -->
<style type="text/css">
    header.intro-header{
        background-image: url('/img/home-bg.jpg')
    }
</style>
<header class="intro-header">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <div class="tags">
                        
                    </div>
                    <h1>ICT멘토링 딥러닝 교육 1일차</h1>
                    <h2 class="subheading">Machine Learning</h2>
                    <span class="meta">
                        Posted by kwon on
                        2019-11-23
                    </span>
                </div>
            </div>
        </div>
    </div>
</header>

<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">

    <!-- Post Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

                <p>저번주에 한이음에서 주최한 머신러닝 ICT멘토링 AI머신러닝(기초) 교육에 이어 이번에는 AI딥러닝 교육에 참가하게 되었다. 이번주도 토일 10:00 ~ 18:00까지 진행되는데 첫째 날은 딥러닝 이론, 케라스, Azure Cloud 설정, MLP 설정에 대해 배웠다.</p>
<h3 id="딥러닝이란"><a href="#딥러닝이란" class="headerlink" title="딥러닝이란?"></a>딥러닝이란?</h3><p>Deep Learning = Deep Neural Network = Artificial Neural Network(ANN) 인공 신경망<br>= Multi Layer Perceptron</p>
<p>인공신경망을 사용하는 머신러닝 모델링 방법 중 하나(Neural Network)이며 다층 인공신경망 구조를 사용하여 빅 데이터 학습한다.</p>
<h4 id="perceptron"><a href="#perceptron" class="headerlink" title="perceptron"></a>perceptron</h4><p>인공 신경망의 한 종류.</p>
<p><strong>단층 퍼셉트론</strong> 은 다수의 신호(Input)을 받아서 하나의 신호(Output)를 출력한다. 이 동작은 뉴런과 아주 유사하고 그 과정은 다음과 같다. 다수의 입력을 받았을 때, 퍼셉트론은 각 입력 신호의 세기에 따라 다른 가중치를 부여한다. 그 결과를 고유한 방식으로 처리한 후, 입력 신호의 합이 일정 값을 초과한다면 그 결과를 다른 뉴련으로 전달한다.</p>
<div style="width: 100%; height: 250px;">
    <img src="https://kyu9341.github.io/img/perceptron.png" style="width: 90%
    ; height: 250px;">
</div>

<p>과거에는 이 퍼셉트론을 하드웨어를 이용하여 구현했다. 이 방식으로도 AND와 OR 문제를 해결이 가능했다. 그러나 이러한 단층 퍼셉트론으로는 XOR문제를 해결할 수 없었다.</p>
<div style="width: 100%; height: 250px;">
    <img src="https://kyu9341.github.io/img/xor.png" style="width: 100%
    ; height: 250px;">
</div>

<p>이러한 문제를 해결할 수 있는 것이 <strong>다층 퍼셉트론</strong> 이다.</p>
<p>딥러닝은 기본적으로 다음과 같은 순서로 진행이 된다.</p>
<p>Weight Initialization -&gt; Forward Propagation -&gt; Back Propagation</p>
<p>And Gate 연산을 예시로 퍼셉트론의 동작 순서에 대해 알아보자.</p>
<p><strong>Weight Initialization (가중치 초기화)</strong> : 예를 들어 노드를 3개를 쌓는다면 입력 값마다 3개의 가중치가 생성된다. 아래의 예시에서는 And Gate에서의 동작을 예로 들었는데 여기서는 0과 1 두개의 노드가 존재하므로 각 입력 값마다 2개의 가중치를 생성하여 계산하였다.</p>
<p><strong>Forward Propagation(순전파)</strong> : 가중치 초기화를 진행한 후에 각각의 입력 값과 가중치 값을 곱해주며 노드(퍼셉트론)에 들어온 값들을 모두 더해 activation function을 적용시켜 출력을 하게 된다. activation function은 threshold값을 지정해 그 값보다 크면 1, 작으면 0이 되는 식으로 동작할 수 있다.</p>
<p>Ex) And gate     <strong>activation function(활성함수)</strong> : ex) [(0.5 &lt; sum) : 1 / (0.5 &gt; sum) : 0]</p>
<table>
<thead>
<tr>
<th align="left"></th>
<th align="left">w1 * x1</th>
<th align="left">w2 * x2</th>
<th align="left">sum</th>
<th align="center">activate function</th>
<th align="right">output</th>
<th align="right">result</th>
</tr>
</thead>
<tbody><tr>
<td align="left">[0, 0]</td>
<td align="left">0.7*0</td>
<td align="left">0.4*0</td>
<td align="left">0</td>
<td align="center">0</td>
<td align="right">0</td>
<td align="right">true</td>
</tr>
<tr>
<td align="left">[1, 0]</td>
<td align="left">0.7*1</td>
<td align="left">0.4*0</td>
<td align="left">0.7</td>
<td align="center">1</td>
<td align="right">0</td>
<td align="right">false</td>
</tr>
<tr>
<td align="left">[0, 1]</td>
<td align="left">0.7*0</td>
<td align="left">0.4*1</td>
<td align="left">0.4</td>
<td align="center">0</td>
<td align="right">0</td>
<td align="right">true</td>
</tr>
<tr>
<td align="left">[1, 1]</td>
<td align="left">0.7*1</td>
<td align="left">0.4*1</td>
<td align="left">1.1</td>
<td align="center">1</td>
<td align="right">1</td>
<td align="right">true</td>
</tr>
</tbody></table>
<p> 세번째 행 : 틀린 결과 -&gt; Weight 재설정</p>
<p><strong>Back Propagation(역전파)</strong> : 위의 표와 같이 activation function을 거쳐 나온 결과값과 실제 값과의 차이를 비교하여 값이 틀렸다면 다시 가중치를 재설정하여 Forward Propagation과정을 반복한다.</p>
<p>예측 값과 실제 값의 차이를 비교하는 과정으로 아래의 cost function이 사용된다.</p>
<ul>
<li><strong>Cost function</strong> (=loss function = error function = objective function)</li>
</ul>
<p>예측 값과 실제 값의 차이를 기반으로 모델의 정확도(성능)을 판단하기 위한 함수로 아래의 수식을 따른다.</p>
<div style="width: 30%; height: 50px;">
    <img src="https://kyu9341.github.io/img/lossfunction.png" style="width:100%
    ; height: 50px;">
</div>

<p>오차를 구하여 모델의 정확도를 판단하는데 이 값이 작을수록 모델의 성능이 좋다는 것을 뜻한다. 그래프로 본다면 아래와 같은데 이 오차를 줄이는 방법으로 경사하강법이 있다.</p>
<h4 id="Gradient-Descent-경사하강법"><a href="#Gradient-Descent-경사하강법" class="headerlink" title="Gradient Descent(경사하강법)"></a>Gradient Descent(경사하강법)</h4><p>해당 함수의 최소값 위치를 찾기 위해 비용함수(Cost Function)의 기울기가 (-)가 되는 방향으로 이동하여 최소값(=기울기 0)을 찾는 알고리즘이다.</p>
<div style="width: 100%; height: 250px;">
    <img src="https://kyu9341.github.io/img/Descent.png" style="width: 100%
    ; height: 250px;">
</div>


<h4 id="Optimizer-최적화기"><a href="#Optimizer-최적화기" class="headerlink" title="Optimizer(최적화기)"></a>Optimizer(최적화기)</h4><p>위에서 말한 최소값을 찾기 위한 방법으로 SGD, Momentum, NAG, Adagrad, Adadelta, Rmsprop, Adam 등의 여러가지 방법이 있는데, SGD는 layer가 늦은 경우 빠르게 찾아주고 데이터가 간단한 경우에 주로 사용한다. Adam은 정확도가 가장 높아서 일반적으로 가장 많이 사용한다고 한다.</p>
<p><strong>optimizer의 발전과정</strong></p>
<div style="width: 100%; height: 250px;">
    <img src="https://kyu9341.github.io/img/optimizer.png" style="width: 90%
    ; height: 250px;">
</div>


<h4 id="Vanishing-Gradient"><a href="#Vanishing-Gradient" class="headerlink" title="Vanishing Gradient"></a>Vanishing Gradient</h4><p>Vanishing Gradient Problem(기울기 값이 사라지는 문제)는 인공신경망을 기울기 값을 베이스로 하는  mothod(backpropagation)로 학습시키려고 할 때 발생하는 문제이다.</p>
<div style="width: 100%; height: 250px;">
    <img src="https://kyu9341.github.io/img/vanishing.png" style="width: 90%
    ; height: 250px;">
</div>

<p>Vanishing Gradient Problem은 activate function을 의존적으로 일어난다. sigmoid함수나 tanh함수를 사용함으로써 발생하는 문제인데 layer가 깊어질수록 전달이 약해진다.<br>이 문제를 해결하기 위해서는 sigmoid함수 대신 ReLU 함수나 Leakey ReLU 등의 함수를 사용하면 된다.</p>
<h4 id="Overfitting"><a href="#Overfitting" class="headerlink" title="Overfitting"></a>Overfitting</h4><p>저번 머신러닝 교육 내용에도 있었지만 역시 딥러닝에도 Overfittin이 존재한다. overfitting은 훈련 데이터에만 정확도가 높아져 새로운 데이터에는 성능이 떨어지는 현상을 말하는데 이를 위한 해결방안으로 다음과 같은 것들이 있다.</p>
<div style="width: 100%; height: 350px;">
    <img src="https://kyu9341.github.io/img/regularization.png" style="width: 80%
    ; height: 350px;">
</div>

<p>–    L1 Regularization  :  세세한 값들은 무시하고 큰 특징들만 추출</p>
<p>–    L2 Regularization  :  세부적인 값들을 약하게 해줌</p>
<div style="width: 100%; height: 350px;">
    <img src="https://kyu9341.github.io/img/dropout.png" style="width: 80%
    ; height: 350px;">
</div>

<dl><dt>–    Dropout : hidden node 중 몇 개를 끊어 냄 -&gt; 똑같은 것만 학습하는 것을 방지</dt><dd>성능이 좋고 많이 사용 (20~50% 노드를 꺼줌)</dd></dl><h4 id="신경망-구조"><a href="#신경망-구조" class="headerlink" title="신경망 구조"></a>신경망 구조</h4><div style="width: 100%; height: 460px;">
    <img src="https://kyu9341.github.io/img/hidden.png" style="width: 80%
    ; height: 450px;">
</div>

<div style="width: 100%; height: 450px;">
    <img src="https://kyu9341.github.io/img/output.png" style="width: 80%
    ; height: 450px;">
</div>
#### 케라스
다음은 딥러닝 프레임워크 중 하나인 케라스를 사용해서 jupyter notebook상에서 실습을 진행하였다. 케라스는 파이썬으로 구현된 high-level deep learning API이며 내부적으로는 TensorFlow로 동작한다. 쉬운 사용법과 간단한 문법으로 빠른 설계가 가능하고 입문자들이 사용해보기 좋다.

<div style="width: 100%; height: 350px;">
    <img src="https://kyu9341.github.io/img/mlt.png" style="width: 80%
    ; height: 350px;">
</div>

<p>실습은 딥러닝 방식중 하나인 MLP 를 사용하였고 AND, XOR 기능을 수행하는 모델을 만들었고 마지막으로 당뇨병 예측 모델을 만들어보았다.</p>
<h3 id="2019-11-23-딥-러닝-과정-Mulit-Layer-Perceptron-MLP"><a href="#2019-11-23-딥-러닝-과정-Mulit-Layer-Perceptron-MLP" class="headerlink" title="2019.11.23. 딥-러닝 과정 Mulit Layer Perceptron(MLP)"></a>2019.11.23. 딥-러닝 과정 Mulit Layer Perceptron(MLP)</h3><h2 id="첫번째-실습-Simple-Keras-모델-생성-학습-AND-Function"><a href="#첫번째-실습-Simple-Keras-모델-생성-학습-AND-Function" class="headerlink" title="첫번째 실습. Simple Keras 모델 생성/학습 - AND Function"></a>첫번째 실습. Simple Keras 모델 생성/학습 - AND Function</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. Numpy 가져오기</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">print(np.__version__)</span><br></pre></td></tr></table></figure>
<pre><code>1.17.0</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 2. 입력/출력 데이터 만들기</span></span><br><span class="line">X = np.array([[<span class="number">0</span>,<span class="number">0</span>], [<span class="number">1</span>,<span class="number">0</span>], [<span class="number">0</span>,<span class="number">1</span>], [<span class="number">1</span>,<span class="number">1</span>]]) <span class="comment"># numpy 형태로 입력 데이터 가져오기</span></span><br><span class="line">y = np.array([[<span class="number">0</span>], [<span class="number">0</span>], [<span class="number">0</span>], [<span class="number">1</span>]]) <span class="comment"># numpy 형태로 출력 데이터 가져오기</span></span><br><span class="line">                                <span class="comment"># 순서 맞춰야함</span></span><br><span class="line">print(X)</span><br><span class="line">print(y)</span><br></pre></td></tr></table></figure>

<pre><code>[[0 0]
 [1 0]
 [0 1]
 [1 1]]
[[0]
 [0]
 [0]
 [1]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 3. Keras 패키지 가져오기</span></span><br><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers.core <span class="keyword">import</span> Dense, Activation</span><br><span class="line"></span><br><span class="line">print(keras.__version__)</span><br></pre></td></tr></table></figure>
<pre><code>2.3.1</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 4. MLP 모델 생성</span></span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line"></span><br><span class="line"><span class="comment"># model.add(Dense(4, input_dim=2)) # 첫번째인자 : node의 개수,  input_dim : feature의 개수 (x1, x2)</span></span><br><span class="line"><span class="comment"># model.add(Activation('relu')) # Activation Function 종류 설정</span></span><br><span class="line"></span><br><span class="line">model.add(Dense(<span class="number">4</span>, input_dim=<span class="number">2</span>, activation=<span class="string">'relu'</span>)) <span class="comment"># 위의 두줄과 완전히 같은 뜻</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># model.add(Dense(1)) # 최종 출력 1개# Dense Layer</span></span><br><span class="line"><span class="comment"># model.add(Activation('sigmoid'))</span></span><br><span class="line"></span><br><span class="line">model.add(Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>)) <span class="comment"># 위의 두줄과 완전히 같은 뜻</span></span><br><span class="line"></span><br><span class="line">print(model.summary())</span><br><span class="line"><span class="comment">#input 값이 2개지만 b도 하나의 값으로 추가되어 4*3 = 12 로 출력된다.</span></span><br><span class="line"><span class="comment"># Dense Layer : fully connected</span></span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;sequential_1&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 4)                 12        
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 5         
=================================================================
Total params: 17
Trainable params: 17
Non-trainable params: 0
_________________________________________________________________
None</code></pre><h4 id="출력층-Output-Layer"><a href="#출력층-Output-Layer" class="headerlink" title="출력층(Output Layer)"></a>출력층(Output Layer)</h4><ul>
<li><p>linear : 특정 값 예측</p>
</li>
<li><p>sigmoid : 이진 클래스 예측</p>
</li>
<li><p>softmax : 다중 클래스 예측</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 5. Compile - Optimizer, Loss function 설정</span></span><br><span class="line"></span><br><span class="line">model.compile(loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">              optimizer=<span class="string">'sgd'</span>,</span><br><span class="line">              metrics=[<span class="string">'accuracy'</span>])</span><br></pre></td></tr></table></figure>

<pre><code>WARNING: Logging before flag parsing goes to stderr.
W1123 21:54:23.066224 11320 deprecation.py:323] From c:\users\kyu93\appdata\local\programs\python\python37\lib\site-packages\tensorflow\python\ops\nn_impl.py:180: add_dispatch_support.&lt;locals&gt;.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 6. 학습시키기</span></span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">1</span></span><br><span class="line">epochs = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"> <span class="comment"># fit : 학습을 시키겠다,  verbose : 1 = 학습 과정을 본다 # shuffle : 한번 풀고 순서를 섞는다</span></span><br><span class="line">model.fit(X, y,</span><br><span class="line">          epochs=epochs,</span><br><span class="line">          batch_size=batch_size,</span><br><span class="line">          shuffle=<span class="literal">True</span>,</span><br><span class="line">          verbose=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/1000
4/4 [==============================] - 0s 1ms/step - loss: 0.3339 - accuracy: 1.0000
Epoch 2/1000
4/4 [==============================] - 0s 992us/step - loss: 0.3319 - accuracy: 1.0000

....

4/4 [==============================] - 0s 868us/step - loss: 0.0205 - accuracy: 1.0000
Epoch 999/1000
4/4 [==============================] - 0s 992us/step - loss: 0.0204 - accuracy: 1.0000
Epoch 1000/1000
4/4 [==============================] - 0s 858us/step - loss: 0.0204 - accuracy: 1.0000

&lt;keras.callbacks.callbacks.History at 0x21a14b58748&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 7. 모델 테스트하기</span></span><br><span class="line">predict = model.predict(np.array([[<span class="number">0</span>,<span class="number">1</span>],])) <span class="comment"># ,해주어야 함 2차원 값임을 알려주기 위해</span></span><br><span class="line">print(predict)</span><br></pre></td></tr></table></figure>
<pre><code>[[0.0208632]]</code></pre><hr>
<h3 id="2019-11-23-딥-러닝-과정-Mulit-Layer-Perceptron-MLP-1"><a href="#2019-11-23-딥-러닝-과정-Mulit-Layer-Perceptron-MLP-1" class="headerlink" title="2019.11.23. 딥-러닝 과정 Mulit Layer Perceptron(MLP)"></a>2019.11.23. 딥-러닝 과정 Mulit Layer Perceptron(MLP)</h3><h2 id="세번째-실습-Keras-모델-생성-학습-당뇨병-예측-모델"><a href="#세번째-실습-Keras-모델-생성-학습-당뇨병-예측-모델" class="headerlink" title="세번째 실습. Keras 모델 생성/학습 - 당뇨병 예측 모델"></a>세번째 실습. Keras 모델 생성/학습 - 당뇨병 예측 모델</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. Pandas 가져오기</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">print(pd.__version__)</span><br></pre></td></tr></table></figure>

<pre><code>0.24.0</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 2. 데이터 불러오기</span></span><br><span class="line">dataset = pd.read_csv(<span class="string">'diabetes_data.csv'</span>)</span><br><span class="line">dataset.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>

<div style="width: 100%; height: 250px;">
    <img src="https://kyu9341.github.io/img/head.png" style="width: 90%
    ; height: 250px;">
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 3. X/y 나누기</span></span><br><span class="line"></span><br><span class="line">X = dataset.iloc[:, :<span class="number">-1</span>]</span><br><span class="line">y = dataset.iloc[:, <span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line">print(X.shape) <span class="comment"># (768, 8) -&gt; 8 : input_dim</span></span><br><span class="line">print(y.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(768, 8)
(768,)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 4. Train set, Test set 나누기</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y,</span><br><span class="line">                                                    test_size=<span class="number">0.3</span>,</span><br><span class="line">                                                    random_state=<span class="number">9</span>)</span><br><span class="line"></span><br><span class="line">X_val, X_test, y_val, y_test = train_test_split(X_test, y_test,</span><br><span class="line">                                               test_size=<span class="number">0.5</span>,</span><br><span class="line">                                               random_state=<span class="number">123</span>)</span><br><span class="line"></span><br><span class="line">print(X_train.shape)</span><br><span class="line">print(y_train.shape)</span><br><span class="line"></span><br><span class="line">print(X_val.shape)</span><br><span class="line">print(y_val.shape)</span><br><span class="line"></span><br><span class="line">print(X_test.shape)</span><br><span class="line">print(y_test.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(537, 8)
(537,)
(115, 8)
(115,)
(116, 8)
(116,)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 5. Keras 패키지 가져오기</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Dropout</span><br><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"></span><br><span class="line">print(keras.__version__)</span><br></pre></td></tr></table></figure>

<pre><code>2.2.4</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 6. MLP 모델 생성</span></span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(<span class="number">12</span>, input_dim=<span class="number">8</span>,</span><br><span class="line">                activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(Dropout(<span class="number">0.3</span>))<span class="comment"># Dropout 설정</span></span><br><span class="line"></span><br><span class="line">model.add(Dense(<span class="number">8</span>, activation=<span class="string">'relu'</span>))<span class="comment"># input_dim은 생략 - (12)로 자동 지정</span></span><br><span class="line">model.add(Dropout(<span class="number">0.5</span>))<span class="comment"># Dropout 설정</span></span><br><span class="line"></span><br><span class="line">model.add(Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</span><br><span class="line"></span><br><span class="line">print(model.summary())</span><br></pre></td></tr></table></figure>

<pre><code>WARNING:tensorflow:From /anaconda/envs/py35/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_7 (Dense)              (None, 12)                108       
_________________________________________________________________
dropout_1 (Dropout)          (None, 12)                0         
_________________________________________________________________
dense_8 (Dense)              (None, 8)                 104       
_________________________________________________________________
dropout_2 (Dropout)          (None, 8)                 0         
_________________________________________________________________
dense_9 (Dense)              (None, 1)                 9         
=================================================================
Total params: 221
Trainable params: 221
Non-trainable params: 0
_________________________________________________________________
None</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 7. Compile - Optimizer, Loss function 설정</span></span><br><span class="line"></span><br><span class="line">model.compile(loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">             optimizer=<span class="string">'adam'</span>,</span><br><span class="line">             metrics=[<span class="string">'accuracy'</span>])</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 8. 학습시키기</span></span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">16</span></span><br><span class="line">epochs = <span class="number">1000</span></span><br><span class="line"><span class="comment"># 한번의 epochs가 끝날 때마다 history에 저장 (데이터 시각화)</span></span><br><span class="line">history = model.fit(X_train, y_train,</span><br><span class="line">         epochs=epochs,</span><br><span class="line">         batch_size=batch_size,</span><br><span class="line">         validation_data=(X_val, y_val), <span class="comment"># validation_set 적용 (꼭 같이 해주는게 좋음)</span></span><br><span class="line">         verbose=<span class="number">1</span>,</span><br><span class="line">         shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Train on 537 samples, validate on 115 samples
Epoch 1/1000
537/537 [==============================] - 1s 970us/step - loss: 4.9289 - acc: 0.5736 - val_loss: 3.2560 - val_acc: 0.6609
Epoch 2/1000
537/537 [==============================] - 0s 88us/step - loss: 3.4709 - acc: 0.6425 - val_loss: 3.2140 - val_acc: 0.6522
Epoch 3/1000
537/537 [==============================] - 0s 81us/step - loss: 3.7243 - acc: 0.5940 - val_loss: 3.0675 - val_acc: 0.6696
Epoch 4/1000

.......

537/537 [==============================] - 0s 91us/step - loss: 0.5624 - acc: 0.7207 - val_loss: 0.5805 - val_acc: 0.7304
Epoch 999/1000
537/537 [==============================] - 0s 97us/step - loss: 0.5566 - acc: 0.7169 - val_loss: 0.5870 - val_acc: 0.7391
Epoch 1000/1000
537/537 [==============================] - 0s 91us/step - loss: 0.5356 - acc: 0.7449 - val_loss: 0.5801 - val_acc: 0.7391</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 9. 모델 평가하기</span></span><br><span class="line">train_accuracy = model.evaluate(X_train, y_train)</span><br><span class="line">test_accuracy = model.evaluate(X_test, y_test)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Train Acc:"</span>, train_accuracy)</span><br><span class="line">print(<span class="string">"Test Acc:"</span>, test_accuracy)</span><br></pre></td></tr></table></figure>

<pre><code>537/537 [==============================] - 0s 21us/step
116/116 [==============================] - 0s 27us/step
Train Acc: [0.5100221896970738, 0.7541899434681045]
Test Acc: [0.725729592915239, 0.6724137972141134]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 10. 학습 시각화하기</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">plt.plot(history.history[<span class="string">'acc'</span>])</span><br><span class="line">plt.plot(history.history[<span class="string">'val_acc'</span>])</span><br><span class="line">plt.title(<span class="string">'Accuracy'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'epoch'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'accuracy'</span>)</span><br><span class="line">plt.legend([<span class="string">'train'</span>,<span class="string">'test'</span>], loc=<span class="string">'upper left'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.plot(history.history[<span class="string">'loss'</span>])</span><br><span class="line">plt.plot(history.history[<span class="string">'val_loss'</span>])</span><br><span class="line">plt.title(<span class="string">'Loss'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'epoch'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'loss'</span>)</span><br><span class="line">plt.legend([<span class="string">'train'</span>,<span class="string">'test'</span>], loc=<span class="string">'upper left'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<div style="width: 100%; height: 400px;">
    <img src="https://kyu9341.github.io/img/output_11_0.png" style="width: 80%
    ; height: 350px;">
</div>

<div style="width: 100%; height: 350px;">
    <img src="https://kyu9341.github.io/img/output_11_1.png" style="width: 80%
    ; height: 350px;">
</div>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 저장하기/불러오기</span></span><br><span class="line">model.save(<span class="string">'my_model.h5'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model</span><br><span class="line">model = load_model(<span class="string">'my_model.h5'</span>)</span><br></pre></td></tr></table></figure>




<p>참조<br><a href="https://ydseo.tistory.com/41" target="_blank" rel="external nofollow noopener noreferrer">https://ydseo.tistory.com/41</a><br><a href="http://research.sualab.com/introduction/2017/10/10/what-is-deep-learning-1.html" target="_blank" rel="external nofollow noopener noreferrer">http://research.sualab.com/introduction/2017/10/10/what-is-deep-learning-1.html</a><br><a href="https://blog.naver.com/minsu_jj/221607901559" target="_blank" rel="external nofollow noopener noreferrer">https://blog.naver.com/minsu_jj/221607901559</a><br><a href="https://hobbang143.blog.me/221469060596" target="_blank" rel="external nofollow noopener noreferrer">https://hobbang143.blog.me/221469060596</a><br><a href="https://gomguard.tistory.com/187" target="_blank" rel="external nofollow noopener noreferrer">https://gomguard.tistory.com/187</a></p>


                <hr>

                

                <ul class="pager">
                    
                        <li class="previous">
                            <a href="/MachineLearning/2019/11/24/2019-11-23-marchinelearning4/" data-toggle="tooltip" data-placement="top" title="ICT멘토링 딥러닝 교육 2일차">&larr; Previous Post</a>
                        </li>
                    
                    
                        <li class="next">
                            <a href="/영상처리/2019/11/22/2019-11-22-ImageProcessing3/" data-toggle="tooltip" data-placement="top" title="디지털 영상처리 - Binary Image, Gamma Correction">Next Post &rarr;</a>
                        </li>
                    
                </ul>

                

                
                <!-- disqus 评论框 start -->
                <div class="comment">
                    <div id="disqus_thread" class="disqus-thread"></div>
                </div>
                <!-- disqus 评论框 end -->
                

            </div>
    <!-- Side Catalog Container -->
        

    <!-- Sidebar Container -->

            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                <!-- Featured Tags -->
                
                <section>
                    <!-- no hr -->
                    <h5><a href="/tags/">FEATURED TAGS</a></h5>
                    <div class="tags">
                       
                    </div>
                </section>
                

                <!-- Friends Blog -->
                
                <hr>
                <h5>FRIENDS</h5>
                <ul class="list-inline">

                    
                        <li><a href="http://blog.kaijun.rocks" target="_blank" rel="external nofollow noopener noreferrer">Kaijun&#39;s Blog</a></li>
                    
                        <li><a href="http://huangxuan.me" target="_blank" rel="external nofollow noopener noreferrer">Hux Blog</a></li>
                    
                        <li><a href="#" target="_blank">Foo</a></li>
                    
                        <li><a href="#" target="_blank">Bar</a></li>
                    
                        <li><a href="#" target="_blank">Example Friends</a></li>
                    
                        <li><a href="#" target="_blank">It helps SEO</a></li>
                    
                </ul>
                
            </div>

        </div>
    </div>
</article>




<!-- disqus 公共JS代码 start (一个网页只需插入一次) -->
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES * * */
    var disqus_shortname = "kyu9341-github-io";
    var disqus_identifier = "https://kyu9341.github.io/MachineLearning/2019/11/23/2019-11-23-marchinelearning3/";
    var disqus_url = "https://kyu9341.github.io/MachineLearning/2019/11/23/2019-11-23-marchinelearning3/";

    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<!-- disqus 公共JS代码 end -->




<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>
<!-- anchor-js, Doc:http://bryanbraun.github.io/anchorjs/ -->
<script>
    async("https://cdn.bootcss.com/anchor-js/1.1.1/anchor.min.js",function(){
        anchors.options = {
          visible: 'always',
          placement: 'right',
          icon: '#'
        };
        anchors.add().remove('.intro-header h1').remove('.subheading').remove('.sidebar-container h5');
    })
</script>
<style>
    /* place left on bigger screen */
    @media all and (min-width: 800px) {
        .anchorjs-link{
            position: absolute;
            left: -0.75em;
            font-size: 1.1em;
            margin-top : -0.1em;
        }
    }
</style>



    <!-- Footer -->
    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                
                
                    <li>
                        <a target="_blank" href="https://twitter.com/Demonbane_x" rel="external nofollow noopener noreferrer">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                
                
                    <li>
                        <a target="_blank" href="https://www.zhihu.com/people/Demonbane" rel="external nofollow noopener noreferrer">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa  fa-stack-1x fa-inverse">知</i>
                            </span>
                        </a>
                    </li>
                

                
                    <li>
                        <a target="_blank" href="http://weibo.com/Demonbane" rel="external nofollow noopener noreferrer">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-weibo fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                
                    <li>
                        <a target="_blank" href="https://www.facebook.com/demonbane.cn" rel="external nofollow noopener noreferrer">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-facebook fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                
                    <li>
                        <a target="_blank" href="https://github.com/kyu9341" rel="external nofollow noopener noreferrer">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                
                    <li>
                        <a target="_blank" href="https://www.linkedin.com/in/kaijun-chen-42089354" rel="external nofollow noopener noreferrer">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-linkedin fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                </ul>
                <p class="copyright text-muted">
                    Copyright &copy; kwon&#39;s Blog 2019 
                    <br>
                    Theme by <a href="http://huangxuan.me" target="_blank" rel="external nofollow noopener noreferrer">Hux</a> 
                    <span style="display: inline-block; margin: 0 5px;">
                        <i class="fa fa-heart"></i>
                    </span> 
                    Ported by <a href="http://blog.kaijun.rocks" target="_blank" rel="external nofollow noopener noreferrer">Kaijun</a> | 
                    <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://ghbtns.com/github-btn.html?user=kaijun&repo=hexo-theme-huxblog&type=star&count=true">
                    </iframe>
                </p>
            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->

<script src="/js/jquery.min.js"></script>


<!-- Bootstrap Core JavaScript -->

<script src="/js/bootstrap.min.js"></script>


<!-- Custom Theme JavaScript -->

<script src="/js/hux-blog.min.js"></script>



<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>

<!-- 
     Because of the native support for backtick-style fenced code blocks 
     right within the Markdown is landed in Github Pages, 
     From V1.6, There is no need for Highlight.js, 
     so Huxblog drops it officially.

     - https://github.com/blog/2100-github-pages-now-faster-and-simpler-with-jekyll-3-0  
     - https://help.github.com/articles/creating-and-highlighting-code-blocks/    
-->
<!--
    <script>
        async("http://cdn.bootcss.com/highlight.js/8.6/highlight.min.js", function(){
            hljs.initHighlightingOnLoad();
        })
    </script>
    <link href="http://cdn.bootcss.com/highlight.js/8.6/styles/github.min.css" rel="stylesheet">
-->


<!-- jquery.tagcloud.js -->
<script>
    // only load tagcloud.js in tag.html
    if($('#tag_cloud').length !== 0){
        async("https://kyu9341.github.io/js/jquery.tagcloud.js",function(){
            $.fn.tagcloud.defaults = {
                //size: {start: 1, end: 1, unit: 'em'},
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>

<!--fastClick.js -->
<script>
    async("https://cdn.bootcss.com/fastclick/1.0.6/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>


<!-- Google Analytics -->


<script>
    // dynamic User by Hux
    var _gaId = 'UA-146069634-1';
    var _gaDomain = 'kyu9341.github.io';

    // Originial
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', _gaId, _gaDomain);
    ga('send', 'pageview');
</script>




<!-- Baidu Tongji -->

<script>
    // dynamic User by Hux
    var _baId = '4cc1f2d8f3067386cc5cdb626a202900';

    // Originial
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?" + _baId;
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
</script>


<!-- Side Catalog -->





<!-- Image to hack wechat -->
<img src="https://kyu9341.github.io/img/icon_wechat.png" width="0" height="0">
<!-- Migrate from head to bottom, no longer block render and still work -->

</body>

</html>
